# Import Packages for Data Manipulation
# Bulk of manipulation will be done in Pandas

import numpy as np
import pandas as pd
from pandas import Series, DataFrame


# Import file from the Target location where the Cognos file is automatically saved down

file = r'\\noamsnyw048\TGT_On_Demand\Nielsen\NIELSEN_MONTHLY_EXTRACT_FF.csv'
data = pd.read_csv(file, sep="|")
sz_file = r'Z:\RevMgmt\RB Projects\AOD Data\Attributions.xlsx'
sz_data = pd.read_excel(sz_file, sheet_name = 'Size')
#,nrows = 100000

# Filter out Unnecessary Brands

brand_filter = ['AMSTEL LIGHT','BIRRA MORETTI ORIGINAL','BOHEMIA ORIGINAL','BUCKLER NEAR BEER','CARTA BLANCA ORIGINAL',
         'DOS EQUIS ESPECIAL LGR','DOS EQUIS AMBER','HEINEKEN ORIGINAL','HEINEKEN LIGHT',"MURPHY'S IRISH STT",
         'NEWCASTLE BRWN ALE','PRESTIGE','RED STRIPE ORIGINAL','SAGRES','STRONGBOW GOLD APPLE','TECATE ORIGINAL',
         'TECATE LIGHT','TIGER ORIGINAL','BUD LIGHT','CORONA LIGHT','CORONA EXTRA','PERONI NASTRO AZZURRO',
         'CORONA FAMILIAR',"BECK'S NEAR BEER",'GUINNESS STT','SUPER BOK','ANGRY ORCHARD CRISP CIDER',
         'SAPPORO','MILLER LITE','STELLA ARTOIS','NEGRA MODELO','MODELO ESPECIAL',
         'STELLA ARTOIS CIDRE','COORS LIGHT','MILLER HIGH LIFE']

mfg_filter = ['ANHEUSER-BUSCH INC.', 'SIERRA NEVADA','CONSTELLATION BRANDS BEER DIV', 'MILLERCOORS', 'BOSTON BEER',
              'HEINEKEN USA', 'MARK ANTHONY BRANDS','SAPPORO BREWERIES LTD','D.G. YUENGLING','DIAGEO/GUINNESS']

container_filter = ['CAN','BOTTLE']

inactive_file = r'Z:\RevMgmt\RB Projects\AOD Data\Attributions.xlsx'
inactive_data = pd.read_excel(inactive_file, sheet_name = 'Remove UPCs',index_col = None)
inactive = inactive_data['UPC'].unique()


data = data[data.MANUFACTURER.isin(mfg_filter)]
data = data[data.CONTAINER.isin(container_filter)]
data = data[data['PRODUCT_SIZE'] != 'REM SIZE']
data = data[~data.UPC_CODE.isin(inactive)]
data = data[data['PCT_ACV_SHARE'] > 1]

# Change the column names for each of the files

cols = (['Market', 'Period','UPC','Brand_Ext','Container','Category','Pack_Size','Size','Brand_Fam','Manufacturer','Country','Dollars','Dollars_LY',
        'EQ','EQ_LY','Price','Price_LY','ACV','ACV_LY','Price Type'])
        
# Set up the price types by dividing up the data set then appending it together in the new format

data_avg = data[['MARKET_DISPLAY_DESC', 'NIELSEN_PERIOD_DESC', 'UPC_CODE','BRAND_EXTENSION', 'CONTAINER', 'CATEGORY', 'PACK_SIZE', 'PRODUCT_SIZE',
                'NIELSEN_BRAND_FAMILY', 'MANUFACTURER', 'COUNTRY', 'SALES_DOL','SALES_DOL_LY', 'SALES_EQ_FACTOR', 'SALES_EQ_FACTOR_LY', 'UNIT_PRICE',
                'UNIT_PRICE_LY','PCT_ACV_SHARE','PCT_ACV_SHARE_LY']]

# Add in Price Type Column
data_avg['Price Type'] = 'Average'

# Rename the columns
data_avg.columns = cols

# Duplicate above process for the Promoted Price Type

# Set up the price types by dividing up the data set then appending it together in the new format

data_promo = data[['MARKET_DISPLAY_DESC', 'NIELSEN_PERIOD_DESC', 'UPC_CODE','BRAND_EXTENSION', 'CONTAINER', 'CATEGORY', 'PACK_SIZE', 'PRODUCT_SIZE',
                'NIELSEN_BRAND_FAMILY', 'MANUFACTURER', 'COUNTRY', 'PROMO_SALES_DOL','PROMO_SALES_DOL_LY', 'PROMO_SALES_EQ_FACTOR', 'PROMO_SALES_EQ_FACTOR_LY', 'PROMO_UNIT_PRICE',
                'PROMO_UNIT_PRICE_LY','PCT_ACV_SHARE','PCT_ACV_SHARE_LY']]

# Add in Price Type Column
data_promo['Price Type'] = 'Promo'

# Rename the columns
data_promo.columns = cols

# Duplicate above process for the No Promo Price Type

# Set up the price types by dividing up the data set then appending it together in the new format

data_no_promo = data[['MARKET_DISPLAY_DESC', 'NIELSEN_PERIOD_DESC', 'UPC_CODE','BRAND_EXTENSION', 'CONTAINER', 'CATEGORY', 'PACK_SIZE', 'PRODUCT_SIZE',
                'NIELSEN_BRAND_FAMILY', 'MANUFACTURER', 'COUNTRY', 'NON_PROMOTED_SALES_DOL','NON_PROMOTED_SALES_DOL_LY', 'NON_PROMO_SALES_EQ_FACTOR', 'NON_PROMO_SALES_EQ_FACTOR_LY', 'NON_PROMO_UNIT_PRICE',
                'NON_PROMO_UNIT_PRICE_LY','PCT_ACV_SHARE','PCT_ACV_SHARE_LY']]

# Add in Price Type Column
data_no_promo['Price Type'] = 'No Promo'

# Rename the columns
data_no_promo.columns = cols


# Append the datasets together
data_final = data_avg

data_final = data_avg.append(data_promo, ignore_index = True)

data_final = data_final.append(data_no_promo, ignore_index = True)

# Add in Units column for later calculations
data_final['Units'] = data_final['Dollars'] / data_final['Price']

data_final = data_final.merge(sz_data["SIZE STANDARD"], left_on = 'Size', right_on = sz_data["NIELSEN SIZE"])


# Concatenate the columns within the file to pivot on
data_final['WAVG_Concat'] = data_final['Market'] + data_final['Container'] + data_final['Pack_Size'] + data_final['SIZE STANDARD'] + data_final['Period'] + data_final['Price Type']


# Filter data for DPL and Pivot the information on Dollars & Unit Price

# Filter on DPL
pvt_prep = data_final.loc[data_final['Brand_Ext'].isin(['BUD LIGHT','MILLER LITE','COORS LIGHT'])] 

# Pivot Data
dpl_pvt = pvt_prep.pivot_table(index = "WAVG_Concat", columns = 'Brand_Ext', values = ['Dollars','Units'], aggfunc = sum,
                               fill_value = 0, margins = True, margins_name = "SubTotal")

# Calculate DPL PTC
dpl_pvt['DPL PTC'] = (dpl_pvt['Dollars']['SubTotal'] / dpl_pvt['Units']['SubTotal'])

# Add the DPL PTC into the full data file to run index calculations
data_final = data_final.merge(dpl_pvt['DPL PTC'], how = 'left', on = 'WAVG_Concat')


# Calculate PTC Index

data_final['PTC Index'] = (data_final['Price'] / data_final['DPL PTC']) * 100

data_final.dropna(subset=['PTC Index'], inplace = True)

# Calcuate SKU Weight of Brand Family

# Concatenate column for pivoting
data_final['Brand_Concat'] = data_final['Market'] + data_final['Brand_Fam'] + data_final['Period'] + data_final['Price Type']

# Pivot data to get volume totals
vol_pvt = data_final.groupby('Brand_Concat').sum().sort_values('Brand_Concat')

# Merge the Total Volume to the data_final dataframe
data_final = data_final.merge(vol_pvt['EQ'], how = 'left', on = 'Brand_Concat')
data_final = data_final.merge(vol_pvt['Dollars'], how = 'left', on = 'Brand_Concat')

# Calculate SKU % of Brand Volume
data_final['Volume_Pct'] = data_final['EQ_x'] / data_final['EQ_y']

# Multiply Index by % to Weight the SKU
data_final['Wtd Index'] = data_final['PTC Index'] * data_final['Volume_Pct']

# Pivot Information based on sum of Wtd Index
wtd_indx = data_final.pivot_table(index='Brand_Concat', values = 'Wtd Index', aggfunc = sum, fill_value = 0)

# Merge into Final Data file
data_final = data_final.merge(wtd_indx['Wtd Index'], how = 'left', on = 'Brand_Concat')

# Set Up Pivot for DPL Brand

# Concatenate the columns within the file to pivot on
data_final['Brand_WAVG_Concat'] = data_final['Market'] + data_final['Period'] + data_final['Price Type']

# Filter on DPL
brand_pvt_prep = data_final.loc[data_final['Brand_Ext'].isin(['BUD LIGHT','MILLER LITE','COORS LIGHT'])] 

# Pivot Data
brand_dpl_pvt = brand_pvt_prep.pivot_table(index = "Brand_WAVG_Concat", columns = 'Brand_Ext', values = ['Dollars_x','EQ_x'], aggfunc = sum,
                               fill_value = 0, margins = True, margins_name = "SubTotal")
                               
# Calculate Brand DPL PTC

brand_dpl_pvt['Brand DPL PTC'] = (brand_dpl_pvt['Dollars_x']['SubTotal'] / brand_dpl_pvt['EQ_x']['SubTotal'])


# Merge into Final Data File

data_final = data_final.merge(brand_dpl_pvt['Brand DPL PTC'], how = 'left', on = 'Brand_WAVG_Concat')

# Calculate Brand PTC

data_final['Brand PTC'] = (data_final['Dollars_y'] / data_final['EQ_y'])

# Calculate Brand Index

data_final['Brand PTC Index'] = (data_final['Brand PTC'] / data_final['Brand DPL PTC']) *100

# Bring in the Region information
mkt_file = r'Z:\RevMgmt\RB Projects\AOD Data\Attributions.xlsx'

mkt = pd.read_excel(mkt_file, sheet_name = 'Markets')

# Merge Region information to the data_final
data_final = data_final.merge(mkt["Region"], left_on = 'Market', right_on = mkt["Markets"])
#mkt.head()


report_filter = ['California Conv','California State Food','Florida Conv','Florida Food','New York Food','New York State Conv',
                'Texas Conv','Texas Food','Total US Conv','Total US Food', 'Walmart Total US TA']
                
                
# Break out data_final into a Region-Specific file
target = r'Z:\RevMgmt\RB Projects\AOD Data\Data\PIM\PIM Data.txt'
data_final.to_csv(target, sep = '|', index = False)

dashboard_tgt = r'Z:\RevMgmt\RB Projects\AOD Data\Data\RM Dashboard\Dashboard Data.txt'
data_final.to_csv(dashboard_tgt, sep = '|', index = False)

data_reporting = data_final[data_final.Market.isin(report_filter)]
data_wer = data_final[data_final['Region'] == 'WER']
data_ner = data_final[data_final['Region'] == 'NER']
data_ser = data_final[data_final['Region'] == 'SER']
data_cer = data_final[data_final['Region'] == 'CER']



# Save down Region-Specific file

wer_target = r'Z:\RevMgmt\RB Projects\AOD Data\Data\PIM\PIM Data WER.txt'
data_wer.to_csv(wer_target, sep='|', index = False)

ner_target = r'Z:\RevMgmt\RB Projects\AOD Data\Data\PIM\PIM Data NER.txt'
data_ner.to_csv(ner_target, sep='|', index = False)

ser_target = r'Z:\RevMgmt\RB Projects\AOD Data\Data\PIM\PIM Data SER.txt'
data_ser.to_csv(ser_target, sep='|', index = False)

cer_target = r'Z:\RevMgmt\RB Projects\AOD Data\Data\PIM\PIM Data CER.txt'
data_cer.to_csv(cer_target, sep='|', index = False)

reporting_target = r'Z:\RevMgmt\RB Projects\AOD Data\Data\PIM\Reporting Data.txt'
data_reporting.to_csv(reporting_target,sep = '|', index = False)



wer_target = r'Z:\RevMgmt\RB Projects\AOD Data\Data\RM Dashboard\Dashboard Data WER.txt'
data_wer.to_csv(wer_target, sep='|', index = False)

ner_target = r'Z:\RevMgmt\RB Projects\AOD Data\Data\RM Dashboard\Dashboard Data NER.txt'
data_ner.to_csv(ner_target, sep='|', index = False)

ser_target = r'Z:\RevMgmt\RB Projects\AOD Data\Data\RM Dashboard\Dashboard Data SER.txt'
data_ser.to_csv(ser_target, sep='|', index = False)

cer_target = r'Z:\RevMgmt\RB Projects\AOD Data\Data\RM Dashboard\Dashboard Data CER.txt'
data_cer.to_csv(cer_target, sep='|', index = False)
